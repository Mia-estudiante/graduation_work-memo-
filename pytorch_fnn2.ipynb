{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "pytorch_fnn2.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyNYqOLMz9YnfocwsD2L4Hl8"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cHNeYfj4sUKm",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1651229380550,
     "user_tz": -540,
     "elapsed": 5452,
     "user": {
      "displayName": "빵수니",
      "userId": "07272002582005504067"
     }
    },
    "outputId": "1155be69-c059-43f2-f783-9dfcc561c1ee",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/gdrive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ],
   "metadata": {
    "id": "rkeP359NsXmY",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1651229455969,
     "user_tz": -540,
     "elapsed": 404,
     "user": {
      "displayName": "빵수니",
      "userId": "07272002582005504067"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#enc_output = 32 x 60 x 768 형태의 tensor 데이터\n",
    "#label = 32 x 1 x 1 형태의 tensor 데이터 "
   ],
   "metadata": {
    "id": "9s4cCORy8zII",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#768차원의 cls 토큰을 6개 라벨로 분류한 후\n",
    "#그 중 제일 큰 값을 가지는 라벨로 매핑\n",
    "#ex) cls 토큰(768차원) --- 감성 분류 후 --> label1(1차원) ====> 768차원으로 늘려주기 \n",
    "class NNModel(nn.Module):\n",
    "    def __init__(self, input_dim, class_size):\n",
    "        super(NNModel,self).__init__()\n",
    "        self.l1 = nn.Linear(input_dim,520) #768차원의 cls token을..\n",
    "        self.l2 = nn.Linear(520,320)\n",
    "        self.l3 = nn.Linear(320,240)\n",
    "        self.l4 = nn.Linear(240,120)\n",
    "        self.l5 = nn.Linear(120, class_size)   #6개로 classification하기 위해..\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        x = F.relu(self.l4(x))\n",
    "        return self.l5(x)"
   ],
   "metadata": {
    "id": "-QFt7FlQFOQO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#######################변수 선언#########################\n",
    "\n",
    "batch_size = 32\n",
    "# total_batch_num = len(총 챗봇 데이터 개수) / batch_size\n",
    "train_batch_size = 4 #32개를 train하기 위해 임의로 설정\n",
    "input_dim = 768\n",
    "class_size = 6\n",
    "epochs = 10000\n",
    "lr = 0.01\n",
    "\n",
    "#######################변수 선언#########################\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = NNModel(input_dim, class_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "for big_batch_num in total_batch_num:\n",
    "  # enc_outputs(tensor) 선언 - encoder에서 output을 받아..\n",
    "  # labels(tensor) 선언 - 해당 시퀀스의 label을 받아..\n",
    "  train_dataset = TensorDataset(enc_outputs, labels)\n",
    "  train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "\n",
    "  for epoch in range(epochs+1):\n",
    "    cost = 0.0\n",
    "    for (step, batch) in enumerate(train_dataloader):\n",
    "      model.train()\n",
    "      batch = tuple(t.cuda() for t in batch)\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      enc_output, label = batch\n",
    "      enc_output = enc_output.view(-1, input_dim).to(device)\n",
    "      label = label.to(device)\n",
    "\n",
    "      hypothesis = model(enc_output)\n",
    "      loss = criterion(hypothesis, label)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      cost += loss\n",
    "  if (epoch+1)%100==0:\n",
    "      print(f\"Epoch : {epoch+1:4d}, Cost : {cost:.3f}\")"
   ],
   "metadata": {
    "id": "dkbfT6sQsWRD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "XbaIsaZT9ZpD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#######################변수 선언#########################\n",
    "\n",
    "sentiment_labels = {0: \"label0\", 1: \"label1\", 2: \"label2\", 3: \"label3\", 4: \"label4\", 5: \"label5\"}\n",
    "# test_data(tensor) 선언 - enc_outputs 중 랜덤으로 가져와..\n",
    "# labels(tensor) 선언 - 해당 test 데이터의 label을 가져와..\n",
    "test_batch_size = 4\n",
    "\n",
    "#######################변수 선언#########################\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    \n",
    "    test_dataset = TensorDataset(test_data, labels)\n",
    "    test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=test_batch_size)\n",
    "\n",
    "    for (step, batch) in enumerate(test_dataloader):\n",
    "      batch = tuple(t.cuda() for t in batch)\n",
    "      enc_output, label = batch\n",
    "\n",
    "      enc_output = enc_output.view(-1, input_dim).to(device)\n",
    "      label = label.to(device)\n",
    "\n",
    "      prediction = model(enc_output)\n",
    "\n",
    "      print('--------------------------------')\n",
    "      print(prediction)\n",
    "      print(torch.round(F.softmax(prediction, dim=1), decimals=2))\n",
    "      print(prediction.argmax(1))\n",
    "      print(list(map(sentiment_labels.get, prediction.argmax(1).tolist())))"
   ],
   "metadata": {
    "id": "w9cMnWSfEYpp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}